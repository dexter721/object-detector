<!DOCTYPE html>
<html lang="th">
<head>
  <meta charset="UTF-8">
  <title>AI Object Detector with Voice</title>
  <style>
    body { text-align: center; font-family: sans-serif; }
    video { border: 2px solid black; width: 80%; max-width: 640px; margin: 10px auto; }
    canvas { display: none; }
  </style>
</head>
<body>
  <h1>กล้องตรวจจับวัตถุพร้อมเสียงพูด</h1>
  <video id="webcam" autoplay muted></video>
  <canvas id="canvas"></canvas>
  <p id="label">กำลังโหลดโมเดล...</p>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.15.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <script>
    const video = document.getElementById('webcam');
    const label = document.getElementById('label');
    let model;

    const labelDict = {
      "chair": "เก้าอี้",
      "couch": "โซฟา", // ถ้ามีเตียงในโมเดลให้ใช้ bed แทน
      "bed": "เตียง",
      "dining table": "โต๊ะ",
      "tv": "ทีวี",
      "cell phone": "โทรศัพท์",
      "book": "หนังสือ",
      "bottle": "ขวด",
      "cup": "ถ้วย",
      "bowl": "ชาม",
      "remote": "รีโมท",
      "mouse": "เมาส์",
      "keyboard": "คีย์บอร์ด",
      "laptop": "โน้ตบุ๊ก",
      "computer": "คอมพิวเตอร์", // coco-ssd ไม่มี label นี้
      "microwave": "ไมโครเวฟ", // แทน หม้อ/กระทะ
      "sports ball": "ลูกบอล",
      "scissors": "กรรไกร",
      "backpack": "กระเป๋า", 
      "teddy bear": "ตุ๊กตา"
    };

    let lastSpokenTimes = {}; // บันทึกเวลาแต่ละวัตถุที่พูดล่าสุด

    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "environment" },
        audio: false
      });
      video.srcObject = stream;
      return new Promise(resolve => {
        video.onloadedmetadata = () => resolve(video);
      });
    }

    function speak(text) {
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = "th-TH";
      speechSynthesis.speak(utter);
    }

    async function detectFrame() {
      const predictions = await model.detect(video);

      if (predictions.length > 0) {
        let found = false;
        for (const prediction of predictions) {
          const name = prediction.class;
          if (labelDict[name]) {
            const thaiName = labelDict[name];
            const now = Date.now();
            if (!lastSpokenTimes[thaiName] || now - lastSpokenTimes[thaiName] > 3000) {
              label.textContent = `พบวัตถุ: ${thaiName}`;
              speak(thaiName);
              lastSpokenTimes[thaiName] = now;
            } else {
              label.textContent = `พบวัตถุ: ${thaiName} (รอพูดใหม่)`;
            }
            found = true;
            break; // พูดทีละชิ้นพอ
          }
        }

        if (!found) {
          label.textContent = "พบวัตถุที่ไม่อยู่ในรายการ (ไม่พูด)";
        }
      } else {
        label.textContent = "ไม่พบวัตถุ";
      }

      requestAnimationFrame(detectFrame);
    }

    async function main() {
      await setupCamera();
      video.play();
      model = await cocoSsd.load();
      label.textContent = "พร้อมตรวจจับแล้ว!";
      detectFrame();
    }

    main();
  </script>
</body>
</html>
